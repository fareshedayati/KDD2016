\relax 
\citation{freund1995desicion}
\citation{breiman2001random}
\citation{friedman2001greedy}
\citation{buitinck2013api}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{\thepage }}
\citation{breiman1984classification}
\@writefile{toc}{\contentsline {section}{\numberline {2}Decision Trees With Dense Input Data}{\thepage }}
\newlabel{sec:background}{{2}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Notation}{\thepage }}
\newlabel{gini}{{1}{\thepage }}
\newlabel{entropy}{{2}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training}{\thepage }}
\newlabel{red}{{3}{\thepage }}
\newlabel{left}{{4}{\thepage }}
\newlabel{right}{{5}{\thepage }}
\newlabel{tree_induction}{{1}{\thepage }}
\newlabel{line_partition}{{12}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}The Optimal Split}{\thepage }}
\newlabel{find_best_split}{{2}{\thepage }}
\newlabel{alg-line:value-extract}{{4}{\thepage }}
\newlabel{line_sorting}{{5}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decision Trees With Sparse Input Data}{\thepage }}
\newlabel{sec:sparse-input-dt}{{3}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sparse matrix format}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Nonzero Values of $\mathcal  {L}_p$}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The array $mapping$ allows to efficiently compute the intersection between the $indices$ array of the csc matrix and a sample set $\mathcal  {L}_p$}}{\thepage }}
\newlabel{fig:mapping}{{1}{\thepage }}
\newlabel{switch}{{7}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The Optimal Split}{\thepage }}
\newlabel{algo:sparse-split}{{3}{\thepage }}
\newlabel{map}{{4}{\thepage }}
\citation{joachims1996probabilistic}
\citation{bay2000archive}
\newlabel{bsearch}{{5}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{\thepage }}
\newlabel{sec:experiments}{{4}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Density}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Real Data}{\thepage }}
\citation{Bache+Lichman:2013}
\citation{Bache+Lichman:2013}
\citation{hastie:book2008}
\citation{breiman1984classification}
\citation{Quinlan:1993:CPM:152181}
\citation{Schapire99improvedboosting}
\citation{das:blog2014}
\citation{Zaharia:2010:SCC:1863103.1863113}
\citation{Chang:2011:LLS:1961189.1961199}
\citation{buitinck2013api}
\bibstyle{abbrv}
\bibdata{references}
\bibcite{Bache+Lichman:2013}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Leveraging the input sparsity significantly speed up decisions tree induction both with shallow and deep trees on the \emph  {20 Newsgroups} dataset. Note that the dataset is very sparse (density = 0.001).}}{\thepage }}
\newlabel{fig:20news}{{2}{\thepage }}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Synthetic Data}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Leveraging the input sparsity significantly speed up decisions tree induction both with shallow and deep trees on the \emph  {cup} dataset. Note that the dataset is quite sparse (density = 0.014).}}{\thepage }}
\newlabel{fig:cup}{{3}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {5}Related Work}{\thepage }}
\newlabel{sec:related}{{5}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{\thepage }}
\newlabel{sec:conclusion}{{6}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {7}Acknowledgment}{\thepage }}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{\thepage }}
\bibcite{bay2000archive}{2}
\bibcite{breiman2001random}{3}
\bibcite{breiman1984classification}{4}
\bibcite{buitinck2013api}{5}
\bibcite{Chang:2011:LLS:1961189.1961199}{6}
\bibcite{das:blog2014}{7}
\bibcite{freund1995desicion}{8}
\bibcite{friedman2001greedy}{9}
\bibcite{hastie:book2008}{10}
\bibcite{joachims1996probabilistic}{11}
\bibcite{pedregosa2011scikit}{12}
\bibcite{Quinlan:1993:CPM:152181}{13}
\bibcite{Schapire99improvedboosting}{14}
\bibcite{Zaharia:2010:SCC:1863103.1863113}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Leveraging the input sparsity does not speed up training of deep trees on the \emph  {adult} dataset. Note that the dataset is quite dense (density = 0.11).}}{\thepage }}
\newlabel{fig:adult}{{4}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Leveraging the input sparsity does not speed up training trees on the \emph  {tic} dataset. Note that the dataset is very dense (density = 0.44).}}{\thepage }}
\newlabel{fig:tic}{{5}{\thepage }}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Significant speed up is achieved by the sparsity-aware decision tree algorithm whenever the density is below 0.2 (or sparsity over 0.8).}}{\thepage }}
\newlabel{fig:density}{{6}{\thepage }}
